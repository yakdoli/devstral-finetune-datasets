#!/usr/bin/env python3
"""
í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê¸°ì¡´ unsloth_dataset ëª¨ë“ˆê³¼ quality_validator ëª¨ë“ˆì˜ í†µí•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from unsloth_dataset import UnslothDatasetGenerator, DatasetConfig, create_dataset_generator
    from quality_validator import QualityValidator, QualityValidatorConfig, create_default_validator
    print("âœ“ ëª¨ë“ˆ ì„í¬íŠ¸ ì„±ê³µ")
except ImportError as e:
    print(f"âœ— ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
    sys.exit(1)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def create_test_data() -> Dict[str, List[Dict[str, Any]]]:
    """í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    test_data = {
        "sharegpt": [
            {
                "conversations": [
                    {"from": "system", "value": "Syncfusion WinForms ì „ë¬¸ê°€"},
                    {"from": "human", "value": "DataGrid ì‚¬ìš©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”."},
                    {"from": "gpt", "value": "DataGrid ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²•:\n1. í”„ë¡œì íŠ¸ì— ì°¸ì¡° ì¶”ê°€\n2. DataGrid ì»¨íŠ¸ë¡¤ í¼ì— ë°°ì¹˜\n3. ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •\n4. ì»¬ëŸ¼ êµ¬ì„±\n5. ìŠ¤íƒ€ì¼ ì ìš©"}
                ]
            },
            {
                "conversations": [
                    {"from": "system", "value": "Syncfusion WinForms ì „ë¬¸ê°€"},
                    {"from": "human", "value": "Chart ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”."},
                    {"from": "gpt", "value": "Chart ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²•:\n1. Chart ì»¨íŠ¸ë¡¤ ì¶”ê°€\n2. Series ì„¤ì •\n3. ë°ì´í„° ë°”ì¸ë”©\n4. ì¶• ì„¤ì •\n5. ë²”ë¡€ ì¶”ê°€"}
                ]
            },
            {
                "conversations": [
                    {"from": "system", "value": "Syncfusion WinForms ì „ë¬¸ê°€"},
                    {"from": "human", "value": "DataGrid ì‚¬ìš©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.."},  # ì¤‘ë³µ êµ¬ë‘ì 
                    {"from": "gpt", "value": "DataGrid ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤..."}  # ì¤‘ë³µ êµ¬ë‘ì 
                ]
            }
        ],
        "alpaca": [
            {
                "instruction": "Syncfusion WinForms DataGrid ì‚¬ìš©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "input": "ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "output": "DataGrid ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²•:\n1. í”„ë¡œì íŠ¸ì— ì°¸ì¡° ì¶”ê°€\n2. DataGrid ì»¨íŠ¸ë¡¤ í¼ì— ë°°ì¹˜\n3. ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •\n4. ì»¬ëŸ¼ êµ¬ì„±\n5. ìŠ¤íƒ€ì¼ ì ìš©"
            },
            {
                "instruction": "Chart ì»´í¬ë„ŒíŠ¸ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„ë¥¼ ë§Œë“œëŠ” ë°©ë²•",
                "input": "ë°ì´í„° ë°”ì¸ë”© í¬í•¨í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "output": "Chart ì»´í¬ë„ŒíŠ¸ ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„± ë°©ë²•:\n1. Chart ì»¨íŠ¸ë¡¤ ì¶”ê°€\n2. Series ì„¤ì •\n3. ë°ì´í„° ë°”ì¸ë”©\n4. ì¶• ì„¤ì •\n5. ë²”ë¡€ ì¶”ê°€"
            },
            {
                "instruction": "DataGrid ì‚¬ìš©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",  # ë¬¸ì¥ ëì— ë§ˆì¹¨í‘œ ì—†ìŒ
                "input": "ì´ˆë³´ìë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                "output": "DataGrid ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²•:\n1. í”„ë¡œì íŠ¸ì— ì°¸ì¡° ì¶”ê°€\n2. DataGrid ì»¨íŠ¸ë¡¤ í¼ì— ë°°ì¹˜\n3. ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •\n4. ì»¬ëŸ¼ êµ¬ì„±\n5. ìŠ¤íƒ€ì¼ ì ìš©"
            }
        ],
        "openai": [
            {
                "messages": [
                    {"role": "system", "content": "Syncfusion WinForms ì „ë¬¸ê°€"},
                    {"role": "user", "content": "DataGrid ì‚¬ìš©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”."},
                    {"role": "assistant", "content": "DataGrid ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²•:\n1. í”„ë¡œì íŠ¸ì— ì°¸ì¡° ì¶”ê°€\n2. DataGrid ì»¨íŠ¸ë¡¤ í¼ì— ë°°ì¹˜\n3. ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •\n4. ì»¬ëŸ¼ êµ¬ì„±\n5. ìŠ¤íƒ€ì¼ ì ìš©"}
                ]
            },
            {
                "messages": [
                    {"role": "system", "content": "Syncfusion WinForms ì „ë¬¸ê°€"},
                    {"role": "user", "content": "Chart ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”."},
                    {"role": "assistant", "content": "Chart ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²•:\n1. Chart ì»¨íŠ¸ë¡¤ ì¶”ê°€\n2. Series ì„¤ì •\n3. ë°ì´í„° ë°”ì¸ë”©\n4. ì¶• ì„¤ì •\n5. ë²”ë¡€ ì¶”ê°€"}
                ]
            },
            {
                "messages": [
                    {"role": "system", "content": "Syncfusion WinForms ì „ë¬¸ê°€"},
                    {"role": "user", "content": "DataGrid ì‚¬ìš©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.."},  # ì¤‘ë³µ êµ¬ë‘ì 
                    {"role": "assistant", "content": "DataGrid ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤..."}  # ì¤‘ë³µ êµ¬ë‘ì 
                ]
            }
        ]
    }
    
    return test_data


def test_unsloth_dataset_generator():
    """UnslothDatasetGenerator í…ŒìŠ¤íŠ¸"""
    print("\n=== UnslothDatasetGenerator í…ŒìŠ¤íŠ¸ ===")
    
    try:
        # ìƒì„±ê¸° ìƒì„±
        config = DatasetConfig(
            target_count=100,
            max_seq_length=4096,
            train_test_split=0.9,
            formats=["sharegpt", "alpaca", "openai"],
            min_tokens=50,
            max_tokens=4096,
            eos_token="</s>",
            remove_duplicates=True,
            quality_threshold=0.7
        )
        
        generator = create_dataset_generator(config)
        print("âœ“ UnslothDatasetGenerator ìƒì„± ì„±ê³µ")
        
        # ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸ (UnslothDatasetGeneratorê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹)
        sample_data = [
            {
                "instruction": "Syncfusion WinForms DataGrid ì‚¬ìš©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "response": "DataGrid ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²•:\n1. í”„ë¡œì íŠ¸ì— ì°¸ì¡° ì¶”ê°€\n2. DataGrid ì»¨íŠ¸ë¡¤ í¼ì— ë°°ì¹˜\n3. ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •\n4. ì»¬ëŸ¼ êµ¬ì„±\n5. ìŠ¤íƒ€ì¼ ì ìš©",
                "quality_score": 0.8,
                "source": "test"
            },
            {
                "instruction": "Chart ì»´í¬ë„ŒíŠ¸ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„ë¥¼ ë§Œë“œëŠ” ë°©ë²•",
                "response": "Chart ì»´í¬ë„ŒíŠ¸ ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„± ë°©ë²•:\n1. Chart ì»¨íŠ¸ë¡¤ ì¶”ê°€\n2. Series ì„¤ì •\n3. ë°ì´í„° ë°”ì¸ë”©\n4. ì¶• ì„¤ì •\n5. ë²”ë¡€ ì¶”ê°€",
                "quality_score": 0.9,
                "source": "test"
            }
        ]
        
        # ë°ì´í„°ì…‹ ìƒì„±
        result = generator.generate_from_samples(sample_data, "test_dataset")
        print("âœ“ ë°ì´í„°ì…‹ ìƒì„± ì„±ê³µ")
        
        # ê²°ê³¼ í™•ì¸
        print(f"ìƒì„±ëœ ë°ì´í„°ì…‹ í¬ë§·: {list(result.train_data.keys())}")
        for format_type, data in result.train_data.items():
            print(f"  {format_type}: {len(data)} ì•„ì´í…œ")
        
        return True
        
    except Exception as e:
        print(f"âœ— UnslothDatasetGenerator í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_quality_validator():
    """QualityValidator í…ŒìŠ¤íŠ¸"""
    print("\n=== QualityValidator í…ŒìŠ¤íŠ¸ ===")
    
    try:
        # í’ˆì§ˆ ê²€ì¦ê¸° ìƒì„±
        validator = create_default_validator()
        print("âœ“ QualityValidator ìƒì„± ì„±ê³µ")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_data = create_test_data()
        print(f"âœ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: {len(test_data)} í¬ë§·, {sum(len(data) for data in test_data.values())} ì•„ì´í…œ")
        
        # ê²€ì¦ ìˆ˜í–‰
        print("ê²€ì¦ ì‹œì‘...")
        validated_datasets = validator.validate_and_filter(test_data)
        print("âœ“ ê²€ì¦ ì™„ë£Œ")
        
        # ê²°ê³¼ í™•ì¸
        print(f"ê²€ì¦ ê²°ê³¼:")
        for format_type, items in validated_datasets.items():
            valid_count = sum(1 for item in items if item.is_valid)
            print(f"  {format_type}: {valid_count}/{len(items)} ì•„ì´í…œ ìœ íš¨")
            
            # ìƒ˜í”Œ ì•„ì´í…œ ì •ë³´ ì¶œë ¥
            if items:
                sample_item = items[0]
                print(f"    ìƒ˜í”Œ ì•„ì´í…œ ID: {sample_item.id}")
                print(f"    ì•ˆì „ ì ìˆ˜: {sample_item.quality_validation.get('safety_score', 0.0):.3f}")
                print(f"    í’ˆì§ˆ ì ìˆ˜: {sample_item.quality_validation.get('quality_score', 0.0):.3f}")
                print(f"    í˜¸í™˜ì„± ì ìˆ˜: {sample_item.quality_validation.get('compatibility_score', 0.0):.3f}")
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = validator.generate_report(validated_datasets)
        print("âœ“ ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± ì„±ê³µ")
        
        # ë¦¬í¬íŠ¸ ìš”ì•½ ì¶œë ¥
        print(f"\në¦¬í¬íŠ¸ ìš”ì•½:")
        print(f"  ì „ì²´ ì•„ì´í…œ: {report['summary']['total_items']}")
        print(f"  ìœ íš¨ ì•„ì´í…œ: {report['summary']['passed_items']}")
        print(f"  ë¬´íš¨ ì•„ì´í…œ: {report['summary']['failed_items']}")
        print(f"  ì „ì²´ ìœ íš¨ìœ¨: {report['summary']['overall_validity_rate']:.2%}")
        
        return True
        
    except Exception as e:
        print(f"âœ— QualityValidator í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_integration():
    """í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\n=== í†µí•© í…ŒìŠ¤íŠ¸ ===")
    
    try:
        # ìƒì„±ê¸° ìƒì„±
        generator_config = DatasetConfig(
            target_count=50,
            max_seq_length=4096,
            train_test_split=0.9,
            formats=["sharegpt", "alpaca", "openai"],
            min_tokens=50,
            max_tokens=4096,
            eos_token="</s>",
            remove_duplicates=True,
            quality_threshold=0.7
        )
        
        generator = create_dataset_generator(generator_config)
        
        # í’ˆì§ˆ ê²€ì¦ê¸° ìƒì„±
        validator = create_default_validator()
        
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„± (UnslothDatasetGeneratorê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹)
        sample_data = [
            {
                "instruction": "Syncfusion WinForms DataGrid ì‚¬ìš©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                "response": "DataGrid ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²•:\n1. í”„ë¡œì íŠ¸ì— Syncfusion ì°¸ì¡° ì¶”ê°€\n2. DataGrid ì»¨íŠ¸ë¡¤ì„ í¼ì— ë°°ì¹˜\n3. ë°ì´í„° ì†ŒìŠ¤(DataTable, BindingSource) ì„¤ì •\n4. ì»¬ëŸ¼ êµ¬ì„± ë° ìŠ¤íƒ€ì¼ ì ìš©\n5. ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ êµ¬í˜„",
                "quality_score": 0.8,
                "source": "test"
            },
            {
                "instruction": "Chart ì»´í¬ë„ŒíŠ¸ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„ë¥¼ ë§Œë“œëŠ” ë°©ë²•",
                "response": "Chart ì»´í¬ë„ŒíŠ¸ ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„±:\n1. Chart ì»¨íŠ¸ë¡¤ í¼ì— ì¶”ê°€\n2. Series(ë°ì´í„° ì‹œë¦¬ì¦ˆ) ì„¤ì •\n3. ë°ì´í„° ë°”ì¸ë”© (DataTable, List ë“±)\n4. Xì¶•, Yì¶• ë ˆì´ë¸” ë° í˜•ì‹ ì„¤ì •\n5. ë²”ë¡€, ì œëª©, ë°°ê²½ ìŠ¤íƒ€ì¼ ì ìš©",
                "quality_score": 0.9,
                "source": "test"
            },
            {
                "instruction": "GridControlì—ì„œ ë°ì´í„° ê·¸ë£¹í™”í•˜ëŠ” ë°©ë²•",
                "response": "GridControl ë°ì´í„° ê·¸ë£¹í™”:\n1. GridControl.DataSource ì„¤ì •\n2. GridView.GroupedColumns ì†ì„± ì‚¬ìš©\n3. ê·¸ë£¹í™” ê¸°ì¤€ ì»¬ëŸ¼ ì§€ì •\n4. ê·¸ë£¹ í—¤ë” ìŠ¤íƒ€ì¼ ì„¤ì •\n5. ê·¸ë£¹ í¼ì¹¨/ì ‘ê¸° ì´ë²¤íŠ¸ ì²˜ë¦¬",
                "quality_score": 0.85,
                "source": "test"
            }
        ]
        
        print("ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘...")
        # ë°ì´í„°ì…‹ ìƒì„±
        result = generator.generate_from_samples(sample_data, "integration_test_dataset")
        print("âœ“ ë°ì´í„°ì…‹ ìƒì„± ì„±ê³µ")
        
        # ìƒì„±ëœ ë°ì´í„° í™•ì¸
        print(f"ìƒì„±ëœ ë°ì´í„°ì…‹:")
        for format_type, data in result.train_data.items():
            print(f"  {format_type}: {len(data)} ì•„ì´í…œ")
        
        # í’ˆì§ˆ ê²€ì¦ ìˆ˜í–‰
        print("\ní’ˆì§ˆ ê²€ì¦ ì‹œì‘...")
        validated_datasets = validator.validate_and_filter(result.train_data)
        print("âœ“ í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ")
        
        # í†µí•© ê²°ê³¼ í™•ì¸
        print(f"\ní†µí•© ê²°ê³¼:")
        total_original = sum(len(data) for data in result.train_data.values())
        total_validated = sum(len(data) for data in validated_datasets.values())
        total_valid = sum(len([item for item in data if item.is_valid]) for data in validated_datasets.values())
        
        print(f"  ì›ë³¸ ë°ì´í„°: {total_original} ì•„ì´í…œ")
        print(f"  ê²€ì¦ ë°ì´í„°: {total_validated} ì•„ì´í…œ")
        print(f"  ìœ íš¨ ë°ì´í„°: {total_valid} ì•„ì´í…œ")
        print(f"  ìœ íš¨ìœ¨: {total_valid/total_original:.2%}")
        
        # ìƒì„¸ ê²°ê³¼ ì¶œë ¥
        for format_type, validated_items in validated_datasets.items():
            print(f"\n{format_type.upper()} í¬ë§· ê²°ê³¼:")
            for i, item in enumerate(validated_items[:2]):  # ìƒìœ„ 2ê°œ ì•„ì´í…œë§Œ ì¶œë ¥
                print(f"  ì•„ì´í…œ {i+1}:")
                print(f"    ID: {item.id}")
                print(f"    ìœ íš¨ ì—¬ë¶€: {item.is_valid}")
                if item.is_valid:
                    print(f"    ì•ˆì „ ì ìˆ˜: {item.quality_validation.get('safety_score', 0.0):.3f}")
                    print(f"    í’ˆì§ˆ ì ìˆ˜: {item.quality_validation.get('quality_score', 0.0):.3f}")
                    print(f"    í˜¸í™˜ì„± ì ìˆ˜: {item.quality_validation.get('compatibility_score', 0.0):.3f}")
                else:
                    print(f"    ë¬´íš¨ ì‚¬ìœ : {item.quality_validation.get('issues', [])}")
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = validator.generate_report(validated_datasets)
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        report_path = "integration_test_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"âœ“ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
        
        return True
        
    except Exception as e:
        print(f"âœ— í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_performance():
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n=== ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        import time
        
        # ëŒ€ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        large_test_data = create_test_data()
        
        # ë°ì´í„° í™•ì¥
        for format_type, items in large_test_data.items():
            large_test_data[format_type] = items * 20  # 20ë°° í™•ì¥
        
        total_items = sum(len(data) for data in large_test_data.values())
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°: {total_items} ì•„ì´í…œ")
        
        # í’ˆì§ˆ ê²€ì¦ê¸° ìƒì„±
        validator = create_default_validator()
        
        # ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        
        print("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        validated_datasets = validator.validate_and_filter(large_test_data)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        # ê²°ê³¼ ë¶„ì„
        total_valid = sum(len([item for item in data if item.is_valid]) for data in validated_datasets.values())
        
        print(f"âœ“ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        print(f"  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
        print(f"  ì²˜ë¦¬ ì†ë„: {total_items/processing_time:.2f} ì•„ì´í…œ/ì´ˆ")
        print(f"  ìœ íš¨ ì•„ì´í…œ: {total_valid}/{total_items} ({total_valid/total_items:.2%})")
        
        return True
        
    except Exception as e:
        print(f"âœ— ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("=== Unsloth Dataset + Quality Validator í†µí•© í…ŒìŠ¤íŠ¸ ===")
    
    # í…ŒìŠ¤íŠ¸ ê²°ê³¼
    test_results = {}
    
    # ê°œë³„ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
    test_results['unsloth_generator'] = test_unsloth_dataset_generator()
    test_results['quality_validator'] = test_quality_validator()
    
    # í†µí•© í…ŒìŠ¤íŠ¸
    test_results['integration'] = test_integration()
    
    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    test_results['performance'] = test_performance()
    
    # ìµœì¢… ê²°ê³¼
    print("\n=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ===")
    passed_tests = sum(test_results.values())
    total_tests = len(test_results)
    
    for test_name, result in test_results.items():
        status = "âœ“ í†µê³¼" if result else "âœ— ì‹¤íŒ¨"
        print(f"{test_name}: {status}")
    
    print(f"\nì „ì²´ ê²°ê³¼: {passed_tests}/{total_tests} í…ŒìŠ¤íŠ¸ í†µê³¼")
    
    if passed_tests == total_tests:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ë¥¼ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
        return True
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)