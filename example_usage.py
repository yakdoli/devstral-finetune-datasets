#!/usr/bin/env python3
"""
ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° í•„í„°ë§ ì‹œìŠ¤í…œ í†µí•© ì‚¬ìš© ì˜ˆì œ

ì´ ì˜ˆì œëŠ” UnslothDatasetGeneratorì™€ QualityValidatorë¥¼ í†µí•©í•˜ì—¬
ê³ í’ˆì§ˆì˜ Unsloth í˜¸í™˜ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ê³  ê²€ì¦í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""

from unsloth_dataset import UnslothDatasetGenerator, DatasetConfig, create_dataset_generator
from quality_validator import QualityValidator, QualityValidatorConfig
import logging
import json
from datetime import datetime

def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

def create_sample_data():
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    return [
        {
            "instruction": "Syncfusion WinForms DataGrid ì‚¬ìš©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "response": "DataGrid ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©ë²•:\n1. í”„ë¡œì íŠ¸ì— Syncfusion ì°¸ì¡° ì¶”ê°€\n2. DataGrid ì»¨íŠ¸ë¡¤ì„ í¼ì— ë°°ì¹˜\n3. ë°ì´í„° ì†ŒìŠ¤(DataTable, BindingSource) ì„¤ì •\n4. ì»¬ëŸ¼ êµ¬ì„± ë° ìŠ¤íƒ€ì¼ ì ìš©\n5. ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ êµ¬í˜„",
            "quality_score": 0.8,
            "source": "test"
        },
        {
            "instruction": "Chart ì»´í¬ë„ŒíŠ¸ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„ë¥¼ ë§Œë“œëŠ” ë°©ë²•",
            "response": "Chart ì»´í¬ë„ŒíŠ¸ ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„±:\n1. Chart ì»¨íŠ¸ë¡¤ í¼ì— ì¶”ê°€\n2. Series(ë°ì´í„° ì‹œë¦¬ì¦ˆ) ì„¤ì •\n3. ë°ì´í„° ë°”ì¸ë”© (DataTable, List ë“±)\n4. Xì¶•, Yì¶• ë ˆì´ë¸” ë° í˜•ì‹ ì„¤ì •\n5. ë²”ë¡€, ì œëª©, ë°°ê²½ ìŠ¤íƒ€ì¼ ì ìš©",
            "quality_score": 0.9,
            "source": "test"
        },
        {
            "instruction": "GridControlì—ì„œ ë°ì´í„° ê·¸ë£¹í™”í•˜ëŠ” ë°©ë²•",
            "response": "GridControl ë°ì´í„° ê·¸ë£¹í™”:\n1. GridControl.DataSource ì„¤ì •\n2. GridView.GroupedColumns ì†ì„± ì‚¬ìš©\n3. ê·¸ë£¹í™” ê¸°ì¤€ ì»¬ëŸ¼ ì§€ì •\n4. ê·¸ë£¹ í—¤ë” ìŠ¤íƒ€ì¼ ì„¤ì •\n5. ê·¸ë£¹ í¼ì¹¨/ì ‘ê¸° ì´ë²¤íŠ¸ ì²˜ë¦¬",
            "quality_score": 0.85,
            "source": "test"
        }
    ]

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    setup_logging()
    logger = logging.getLogger(__name__)
    
    logger.info("=== ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° í•„í„°ë§ ì‹œìŠ¤í…œ í†µí•© ì˜ˆì œ ===")
    
    # 1. ë°ì´í„°ì…‹ ìƒì„±ê¸° ì´ˆê¸°í™”
    logger.info("1. ë°ì´í„°ì…‹ ìƒì„±ê¸° ì´ˆê¸°í™”...")
    generator_config = DatasetConfig(
        target_count=100,
        max_seq_length=8192,
        train_test_split=0.9,
        formats=["sharegpt", "alpaca", "openai"],
        min_tokens=50,
        max_tokens=8192,
        eos_token="</s>",
        remove_duplicates=True,
        quality_threshold=0.7,
        batch_size=10,
        max_workers=8,
        seed=42,
        output_dir="output/dataset",
        include_metadata=True,
        shuffle_data=True
    )
    
    generator = create_dataset_generator(generator_config)
    
    # 2. í’ˆì§ˆ ê²€ì¦ê¸° ì´ˆê¸°í™”
    logger.info("2. í’ˆì§ˆ ê²€ì¦ê¸° ì´ˆê¸°í™”...")
    validator_config = QualityValidatorConfig(
        min_quality_score=0.7,
        max_similarity_threshold=0.9,
        safety_threshold=0,
        enable_auto_correction=True,
        enable_statistics_analysis=True,
        batch_size=10,
        max_workers=8,
        output_format="enhanced",
        include_metadata=True,
        generate_report=True
    )
    validator = QualityValidator(validator_config)
    
    # 3. ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    logger.info("3. ìƒ˜í”Œ ë°ì´í„° ìƒì„±...")
    sample_data = create_sample_data()
    logger.info(f"ìƒì„±ëœ ìƒ˜í”Œ ë°ì´í„°: {len(sample_data)}ê°œ")
    
    # 4. ë°ì´í„°ì…‹ ìƒì„±
    logger.info("4. ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘...")
    raw_datasets = generator.generate_from_samples(sample_data, "test_dataset")
    
    # ìƒì„±ëœ ë°ì´í„°ì…‹ ì •ë³´ ì¶œë ¥
    logger.info("=== ìƒì„±ëœ ë°ì´í„°ì…‹ ì •ë³´ ===")
    for format_type, data in raw_datasets.train_data.items():
        logger.info(f"{format_type}: {len(data)}ê°œ í›ˆë ¨ ë°ì´í„°")
    for format_type, data in raw_datasets.validation_data.items():
        logger.info(f"{format_type}: {len(data)}ê°œ ê²€ì¦ ë°ì´í„°")
    
    # 5. í’ˆì§ˆ ê²€ì¦ ë° í•„í„°ë§
    logger.info("5. í’ˆì§ˆ ê²€ì¦ ë° í•„í„°ë§ ì‹œì‘...")
    
    # DatasetGenerationResultë¥¼ QualityValidatorê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    datasets_for_validation = {}
    for format_type in ["sharegpt", "alpaca", "openai"]:
        train_data = raw_datasets.train_data.get(format_type, [])
        val_data = raw_datasets.validation_data.get(format_type, [])
        datasets_for_validation[format_type] = train_data + val_data
    
    validated_datasets = validator.validate_and_filter(datasets_for_validation)
    
    # 6. ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±
    logger.info("6. ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±...")
    validation_report = validator.generate_report(validated_datasets)
    
    # 7. ê²°ê³¼ ì¶œë ¥
    logger.info("=== ê²€ì¦ ê²°ê³¼ ìš”ì•½ ===")
    logger.info(f"ë¦¬í¬íŠ¸ í‚¤: {list(validation_report['summary'].keys())}")
    logger.info(f"ì „ì²´ ì•„ì´í…œ: {validation_report['summary']['total_items']}")
    logger.info(f"í†µê³¼ ì•„ì´í…œ: {validation_report['summary']['passed_items']}")
    logger.info(f"ì‹¤íŒ¨ ì•„ì´í…œ: {validation_report['summary']['failed_items']}")
    logger.info(f"ì „ì²´ ìœ íš¨ìœ¨: {validation_report['summary']['overall_validity_rate']:.2f}%")
    
    # 8. ìƒì„¸ ê²°ê³¼ ì¶œë ¥
    logger.info("=== ë¦¬í¬íŠ¸ ì „ì²´ êµ¬ì¡° ===")
    logger.info(f"ë¦¬í¬íŠ¸ í‚¤: {list(validation_report.keys())}")
    
    if 'format_statistics' in validation_report:
        logger.info("=== í¬ë§·ë³„ ìƒì„¸ ê²°ê³¼ ===")
        for format_type, result in validation_report['format_statistics'].items():
            logger.info(f"{format_type}:")
            logger.info(f"  ì „ì²´ ì•„ì´í…œ: {result['total']}")
            logger.info(f"  ìœ íš¨ ì•„ì´í…œ: {result['valid']}")
            logger.info(f"  ë¬´íš¨ ì•„ì´í…œ: {result['invalid']}")
            logger.info(f"  ìœ íš¨ìœ¨: {result['validity_rate']:.2f}%")
    
    # 9. ê²€ì¦ëœ ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥
    logger.info("=== ê²€ì¦ëœ ë°ì´í„° ìƒ˜í”Œ ===")
    for format_type, data in validated_datasets.items():
        if data:
            sample_item = data[0]
            logger.info(f"{format_type} í¬ë§· ìƒ˜í”Œ:")
            logger.info(f"  ID: {sample_item.id}")
            logger.info(f"  ì•ˆì „ ì ìˆ˜: {sample_item.quality_validation.get('safety_score', 'N/A')}")
            logger.info(f"  í’ˆì§ˆ ì ìˆ˜: {sample_item.quality_validation.get('quality_score', 'N/A')}")
            logger.info(f"  ì¤‘ë³µ ìƒíƒœ: {sample_item.quality_validation.get('duplicate_status', 'N/A')}")
            logger.info(f"  Unsloth í˜¸í™˜ì„±: {sample_item.quality_validation.get('unsloth_compatible', 'N/A')}")
            break
    
    # 10. ìµœì¢… ê²°ê³¼ ì €ì¥
    logger.info("10. ìµœì¢… ê²°ê³¼ ì €ì¥...")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ê²€ì¦ ë¦¬í¬íŠ¸ ì €ì¥
    report_path = f"output/validation_report_{timestamp}.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(validation_report, f, ensure_ascii=False, indent=2)
    logger.info(f"ê²€ì¦ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
    
    # ê²€ì¦ëœ ë°ì´í„°ì…‹ ì €ì¥
    for format_type, data in validated_datasets.items():
        if data:
            dataset_path = f"output/validated_{format_type}_dataset_{timestamp}.jsonl"
            with open(dataset_path, 'w', encoding='utf-8') as f:
                for item in data:
                    # ValidationResult ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                    if hasattr(item, '__dict__'):
                        item_dict = vars(item)
                    else:
                        item_dict = item
                    f.write(json.dumps(item_dict, ensure_ascii=False) + '\n')
            logger.info(f"ê²€ì¦ëœ {format_type} ë°ì´í„°ì…‹ ì €ì¥: {dataset_path}")
    
    logger.info("=== ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° í•„í„°ë§ ì‹œìŠ¤í…œ í†µí•© ì˜ˆì œ ì™„ë£Œ ===")
    
    return {
        "generator_config": generator_config,
        "validator_config": {
            "min_quality_score": validator.config.min_quality_score,
            "max_similarity_threshold": validator.config.max_similarity_threshold,
            "safety_threshold": validator.config.safety_threshold,
            "enable_auto_correction": validator.config.enable_auto_correction
        },
        "validation_report": validation_report,
        "validated_datasets": validated_datasets
    }

if __name__ == "__main__":
    try:
        result = main()
        print("\nğŸ‰ í†µí•© ì˜ˆì œ ì‹¤í–‰ ì„±ê³µ!")
        print(f"ìµœì¢… ìœ íš¨ ë°ì´í„°ì…‹ í¬ê¸°: {sum(len(data) for data in result['validated_datasets'].values())}")
    except Exception as e:
        print(f"\nâŒ í†µí•© ì˜ˆì œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()